{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cp4v5tuMFSdq",
        "outputId": "c3491d56-cec8-4cd1-e518-32a18df61ffd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit==1.35.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: langchain==0.2.14 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.2.14)\n",
            "Requirement already satisfied: langchain-core==0.2.39 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.2.39)\n",
            "Requirement already satisfied: langchain-community==0.2.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.2.12)\n",
            "Requirement already satisfied: langchain_groq==0.1.9 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.1.9)\n",
            "Requirement already satisfied: pandas==2.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: pyngrok==7.2.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (7.2.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (10.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit==1.35.0->-r requirements.txt (line 1)) (6.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (3.11.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.14->-r requirements.txt (line 2)) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.39->-r requirements.txt (line 3)) (1.33)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.12->-r requirements.txt (line 4)) (0.6.7)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain_groq==0.1.9->-r requirements.txt (line 5)) (0.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.2->-r requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.0.2->-r requirements.txt (line 6)) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.14->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (1.23.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements.txt (line 4)) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.35.0->-r requirements.txt (line 1)) (4.0.12)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.39->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14->-r requirements.txt (line 2)) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.14->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.14->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.14->-r requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.2->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit==1.35.0->-r requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit==1.35.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit==1.35.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit==1.35.0->-r requirements.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit==1.35.0->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit==1.35.0->-r requirements.txt (line 1)) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.14->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.35.0->-r requirements.txt (line 1)) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq==0.1.9->-r requirements.txt (line 5)) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.35.0->-r requirements.txt (line 1)) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.35.0->-r requirements.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.12->-r requirements.txt (line 4)) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vsc9NtYoT1ey"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_utf8_encoding(data):\n",
        "  if isinstance(data, str):\n",
        "    return data.encode('utf-8', 'replace').decode('utf-8')\n",
        "  elif isinstance(data, list):\n",
        "    return [ensure_utf8_encoding(item) for item in data]\n",
        "  elif isinstance(data, dict):\n",
        "    return {key: ensure_utf8_encoding(value) for key, value in data.items()}\n",
        "  else:\n",
        "    return data\n",
        "\n",
        "with open(\"/content/raw_posts.json\", encoding='utf-8') as f:\n",
        "  posts = json.load(f)\n",
        "posts = ensure_utf8_encoding(posts)"
      ],
      "metadata": {
        "id": "8hJvIgIAT5LH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for post in posts:\n",
        "  print(post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhFxgrXnUT-Q",
        "outputId": "984b074a-2542-44c4-f1e8-05b9cf80c674"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \"Just saw a LinkedIn Influencer with 'Organic Growth' written in the profile with 65K+ followers claiming that he can help you in growing your platform, copying the posts from other influencers.\", 'engagement': 90}\n",
            "{'text': \"Jobseekers, this oneâ€™s for you.\\n Every application, every interview, every follow-upâ€¦ the pressure is immense.\\n And I know what you're thinking: Am I not good enough? \\n But let me tell you, this isnâ€™t about you or your skills. Itâ€™s about a broken system where 60% of applicants never hear back. \\n Your mental health is not worth sacrificing for a system that doesnâ€™t acknowledge your worth. \\n Please remember, taking care of yourself is the real priority. \\n Your dream job will come, but for now, breathe. ðŸŒ»\", 'engagement': 347}\n",
            "{'text': 'Looking for jobs on LinkedIn is like online dating: Full of promises, but in the end, youâ€™re just left ghosted.', 'engagement': 109}\n",
            "{'text': \"LinkedIn scams be like: 'Congratulations, you've been selected for a role you didnâ€™t even apply for!' \\n The catch? Pay Rs. 50,000 for the honor.\", 'engagement': 115}\n",
            "{'text': \"sapne dekhna achi baat hai,\\nlekin job ka sapna dekh ke 'interested' likhna,\\nyeh toh achi baat nahi hai na?\", 'engagement': 545}\n",
            "{'text': \"Next time when I'll be reading some LinkedIn Influencer's story, I am starting from the last line.\\nIf there's a link attached to it, it's most probably a fake one.\\nSaves me time!\", 'engagement': 188}\n",
            "{'text': \"Every time I poured my heart into 5-6 rounds of interviews and faced rejection, it felt like a punch in the gut. The sleepless nights, the endless preparation, all for nothing.\\n\\nBut looking back, I realize it wasnâ€™t nothing. It was the Universeâ€™s way of saying, â€œNot this one, something better is on the way.â€\\n\\nEvery single time, Iâ€™ve been shown why that rejection happened.\\n\\nDoors I thought I wanted to walk through were shut, only to have the right ones swing open.\\n\\nThe kind that aligned with my growth, my values, and my happiness.\\n\\nAt first, it stung. It hurt deeply. But now, when things donâ€™t go as planned, I donâ€™t panic.\\n\\nI donâ€™t question my worth. I sit back, breathe, and trust. The Universe knows.\\n\\nI know there's another plan waiting. Something bigger, better, and just for me.\\n\\nTo anyone feeling the weight of rejection: trust that the closed doors are protecting you from something you canâ€™t see right now.\\n\\nYour path is being cleared for something even more beautiful.\", 'engagement': 206}\n",
            "{'text': \"To everyone who's still looking for a job...\\n\\nI see you. I feel you. ðŸ’”\\n\\nEvery rejection email feels like a punch in the gut, and every 'We'll get back to you' sounds more like 'You'll never hear from us.'\\n\\nBut I want you to know, you're not alone in this. ðŸŒ¸\\n\\nAccording to a study, 80% of jobseekers struggle with anxiety and self-doubt during their search. It's normal to feel lost, but it's not the end.\\n\\nTake breaks, breathe, and remember, this doesn't define you. Your worth is not tied to an offer letter. ðŸ’¥\\n\\nYour mental health matters more than any job.\", 'engagement': 899}\n",
            "{'text': \"Sometimes, we forget that a companyâ€™s brand name doesnâ€™t define someoneâ€™s talent. Itâ€™s easy to get caught up in the 'big company = big talent' mindset, but that's not always the case.\\n\\nIâ€™ve had the privilege of working with people from smaller companies (lesser known) who blow me away with their skills and dedication. They donâ€™t need a fancy title or a famous brand behind them to prove their worth.\\n\\nI've seen the other side tooâ€”people in top-tier companies feeling lost, overwhelmed, or stuck, even though the world sees them as 'successful'.\\n\\nLetâ€™s stop attaching someoneâ€™s value to the company they work for. Freshers especially need to hear thisâ€”skills are what matter, not the size of the company behind them.\\n\\nAt the end of the day, happiness and growth donâ€™t come from a brand name, they come from doing what you love and constantly improving your craft.\", 'engagement': 166}\n",
            "{'text': \"So when I left a toxic work environment, I told my manager a simple thing and felt so good ðŸ˜¯\\n\\nI just said-\\n\\n'Hope your son gets a manager like you.\\nI hope that the manager behaves the same way as you did with me.\\nThank you.'\\n\\nNow tell me 1 thing-\\n\\nShe always said that she was a great manager.\\nWhy will she get offended?\\n\\nI just told her that I wish her son would get a manager like she was.\\n\\nIf you felt bad, then that means you were a bad manager and now you know it. ?\\x0880\\n\\nIf you feel good, then take it as a blessing for your son and you'll really want someone to treat your son/daughter in the same way.\\n\\nShe cannot be even angry with me else it'll prove that she was not a 'great' manager.\\n\\nMuskan - 1\\nManager - 0\\n\\nMuskan -> Aura +100000000\\n\\n(Fictional message unfortunately :(\\n)\\n\\nHope you all become the people that your sons/daughters will like to work under ðŸ™\\n\\nThere are a lot of bad people/things, bring a small change and break the chain :)\", 'engagement': 1111}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "jMSjJ61DUvnf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(groq_api_key = GROQ_API_KEY, model_name = 'llama-3.3-70b-versatile')"
      ],
      "metadata": {
        "id": "nS_OsJW6buJS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking LLM activation\n",
        "if __name__ == \"__main__\":\n",
        "  response = llm.invoke(\"which are top 3 pillars of a country's economy. Share in less than 50 words\")\n",
        "  print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua_-wI47cAPq",
        "outputId": "1c95af5d-3434-4190-e422-73f76ab1b298"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 3 pillars of a country's economy are: \n",
            "1. Industry\n",
            "2. Services\n",
            "3. Agriculture\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "json_parser = JsonOutputParser()"
      ],
      "metadata": {
        "id": "0GVJC-SIfamb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_posts(raw_file_path, processed_file_path=None):\n",
        "  enriched_posts = []\n",
        "  for post in posts:\n",
        "    mdata = metadata(post['text'])\n",
        "    post_with_metadata = post | mdata\n",
        "    enriched_posts.append(post_with_metadata)\n",
        "    unified_tags = get_unified_tags(enriched_posts)\n",
        "    for post in enriched_posts:\n",
        "        current_tags = post['tags']\n",
        "        new_tags = {unified_tags[tag] for tag in current_tags if tag in unified_tags}\n",
        "        post['tags'] = list(new_tags)\n",
        "    with open(processed_file_path, encoding='utf-8', mode=\"w\") as outfile:\n",
        "      json.dump(enriched_posts, outfile, indent=4)"
      ],
      "metadata": {
        "id": "2f8pLm2qjwy0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metadata(post):\n",
        "  template = '''\n",
        "    You are given a LinkedIn post. You need to extract number of lines, language of the post and tags.\n",
        "    1. Return a valid JSON. No preamble.\n",
        "    2. JSON object should have exactly three keys: line_count, language and tags.\n",
        "    3. tags is an array of text tags. Extract maximum two tags.\n",
        "    4. Each tag should be enclosed in double quotes.\n",
        "    5. Language should be English or Hinglish (Hinglish means hindi + english)\n",
        "\n",
        "    Here is the actual post on which you need to perform this task:\n",
        "    {post}\n",
        "    '''\n",
        "  prompttemplate = PromptTemplate.from_template(template)\n",
        "  chain = prompttemplate|llm\n",
        "  response = chain.invoke(input = {\"post\":post})\n",
        "  try:\n",
        "    res = json_parser.parse(response.content)\n",
        "  except OutputParserException:\n",
        "    raise OutputParserException(\"1. LLM Returned Code instead of JSON OR Context too big. Unable to Parso jobs\")\n",
        "  return res"
      ],
      "metadata": {
        "id": "INWtChpOfvm6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unified_tags(posts_with_metadata):\n",
        "    unique_tags = set()\n",
        "    # Loop through each post and extract the tags\n",
        "    for post in posts_with_metadata:\n",
        "        unique_tags.update(post['tags'])  # Add the tags to the set\n",
        "\n",
        "    unique_tags_list = ','.join(unique_tags)\n",
        "\n",
        "    template = '''I will give you a list of tags. You need to unify tags with the following requirements,\n",
        "    1. Tags are unified and merged to create a shorter list.\n",
        "       Example 1: \"Jobseekers\", \"Job Hunting\" can be all merged into a single tag \"Job Search\".\n",
        "       Example 2: \"Motivation\", \"Inspiration\", \"Drive\" can be mapped to \"Motivation\"\n",
        "       Example 3: \"Personal Growth\", \"Personal Development\", \"Self Improvement\" can be mapped to \"Self Improvement\"\n",
        "       Example 4: \"Scam Alert\", \"Job Scam\" etc. can be mapped to \"Scams\"\n",
        "       Example 5: \"sapna\" can be mapped to \"Mental Health\"\n",
        "    2. Each tag should be follow title case convention. example: \"Motivation\", \"Job Search\"\n",
        "    3. Output should be a strictly a JSON object, No preamble.\n",
        "    3. Output should have mapping of original tag and the unified tag.\n",
        "       For example: {{\"Jobseekers\": \"Job Search\",  \"Job Hunting\": \"Job Search\", \"Motivation\": \"Motivation}}\n",
        "       Here is the list of tags:\n",
        "        {tags}\n",
        "       '''\n",
        "    pt = PromptTemplate.from_template(template)\n",
        "    chain = pt | llm\n",
        "    response = chain.invoke(input={\"tags\": str(unique_tags_list)})\n",
        "    try:\n",
        "      json_parser = JsonOutputParser()\n",
        "      res = json_parser.parse(response.content)\n",
        "    except OutputParserException:\n",
        "      raise OutputParserException(\"2.Context too big. Unable to parse jobs.\")\n",
        "    return res"
      ],
      "metadata": {
        "id": "Sc_qY1EntLQf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  process_posts(\"/content/raw_posts.json\",\"/content/drive/MyDrive/Linkedin_Post_Generator/Processed_posts.json\")\n"
      ],
      "metadata": {
        "id": "oVwAt7G2-XqG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('app.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from few_shots import FewShotPosts\n",
        "from post_generator import generate_post\n",
        "fs = FewShotPosts()\n",
        "tags = fs.get_tags()\n",
        "\n",
        "\n",
        "length_options = [\"Short\", \"Medium\", \"Long\"]\n",
        "language_options = [\"English\", \"Hinglish\",\"Hindi\",\"French\",\"German\"]\n",
        "\n",
        "\n",
        "st.title('LinkedIn Post Generator')\n",
        "\n",
        "# Create columns for user input\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "    selected_tag = st.selectbox(\"Select Topic\", options=tags)\n",
        "with col2:\n",
        "    selected_length = st.selectbox(\"Select Length\", options=length_options)\n",
        "with col3:\n",
        "    selected_language = st.selectbox(\"Select Language\", options=language_options)\n",
        "\n",
        "# Generate post when button is clicked\n",
        "if st.button(\"Generate\"):\n",
        "    post = generate_post(selected_tag, selected_length, selected_language)\n",
        "    st.write(post)\n",
        "\"\"\")\n",
        "\n",
        "# Now run the Streamlit app using nohup (background execution)\n",
        "!nohup streamlit run app.py &>/dev/null &\n",
        "\n",
        "# Install Pyngrok if it's not installed already\n",
        "# !pip install pyngrok\n",
        "\n",
        "# Set up ngrok for external access\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set the ngrok auth token\n",
        "ngrok.set_auth_token(\"2rJSBgtMeqqHBmWXXAw4RxlcCoz_Arm2Vt6JQjQyFZFRiXuz\")\n",
        "\n",
        "# Open a tunnel to the Streamlit app running on port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "print(f\"Streamlit app is live at {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1oGCsGuGnMT",
        "outputId": "7b9dc20c-c7aa-4150-e14a-610d97cbba57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at NgrokTunnel: \"https://4f7b-35-194-214-9.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUeMYSA6EYBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}